This project focuses on developing a machine learning model to recognize specific sign language gestures, namely the letters A, B, C, Del, Nothing, and Space.
Using a convolutional neural network (CNN) algorithm, the model is trained on 64x64 grayscale images from a custom dataset. 
The goal is to provide a reliable solution that operates from 6 PM to 10 PM, 
enabling efficient real-time video detection and image upload through a Graphical User Interface (GUI) designed with Tkinter.

Supported Python Version : Python 3.7.16

Run Sign language Detection Train.ipynb to train model : https://github.com/eldhoeliaszachariah/Sign-Language-Detection-/blob/main/Sign%20language%20Detection%20Train.ipynb


![Output](https://github.com/user-attachments/assets/20b77de4-ccff-4590-8f86-3113871cabe4)



Run GUI.py file for start detection : https://github.com/eldhoeliaszachariah/Sign-Language-Detection-/blob/main/GUI.py
![image](https://github.com/user-attachments/assets/472aaa13-5f13-48bf-a79a-bf6b68347178)
