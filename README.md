This project focuses on developing a machine learning model to recognize specific sign language gestures, namely the letters A, B, C, Del, Nothing, and Space.
Using a convolutional neural network (CNN) algorithm, the model is trained on 64x64 grayscale images from a custom dataset. 
The goal is to provide a reliable solution that operates from 6 PM to 10 PM, 
enabling efficient real-time video detection and image upload through a Graphical User Interface (GUI) designed with Tkinter.
![Output](https://github.com/user-attachments/assets/d59e96c1-5849-4044-9da1-05bae560a25d)


Output : 
![image](https://github.com/user-attachments/assets/a368af94-d196-4725-8af4-b80ce6edbe25)


Run real time image & video recognition .py file for start detection 
![image](https://github.com/user-attachments/assets/69769b82-19aa-438d-ab3d-97fd865e494f)
